{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "def dump_yaml(data, filename):\n",
    "    Dumper = yaml.SafeDumper\n",
    "    Dumper.ignore_aliases = lambda self, data: True\n",
    "    with open(filename, 'w', encoding='utf8') as f:\n",
    "        yaml.dump(data, f, Dumper = Dumper,\n",
    "                  default_flow_style=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_mappings(r):\n",
    "    to_iso = \"../data-raw/afrobarometer_to_iso/r%d.yml\" % r\n",
    "    to_wals = \"../data-raw/afrobarometer_to_wals/r%d.yml\" % r\n",
    "    out = \"../data-raw/afrobarometer-mappings/r%d.yml\" % r\n",
    "    with open(to_wals, 'r') as f:\n",
    "        data_wals = yaml.load(f)\n",
    "\n",
    "    with open(to_iso, 'r') as f:\n",
    "        data_iso = yaml.load(f)\n",
    "        \n",
    "    newdata = {}\n",
    "    for row in data_iso:\n",
    "        try:\n",
    "            key = (row['lang_id'], tuple(sorted(row['question'])))\n",
    "        except KeyError as e:\n",
    "            print(row)\n",
    "            raise e\n",
    "        row['wals_code'] = None\n",
    "        newdata[key] = row   \n",
    "        \n",
    "    for row in data_wals:\n",
    "        try:\n",
    "            key = (row['lang_id'], tuple(sorted(row['question'])))\n",
    "        except KeyError as e:\n",
    "            print(row)\n",
    "            raise e\n",
    "        try:\n",
    "            newdata[key]['wals_code'] = row['wals_code']\n",
    "        except KeyError as e:\n",
    "            print(row)\n",
    "            # raise e\n",
    "\n",
    "    newdata = sorted([x for x in newdata.values()], key = lambda x: (x['lang_id'], tuple(sorted(x['question']))))\n",
    "    for row in newdata:\n",
    "        row['question'] = sorted(row['question'])\n",
    "        row['iso_639_3'] = sorted(row['iso_639_3'])\n",
    "        if row['wals_code'] is not None:\n",
    "            row['wals_code'] = sorted(row['wals_code'])\n",
    "        if 'note' in row and row['note'] is not None:\n",
    "            row['note'] = row['note'].strip()\n",
    "    \n",
    "    dump_yaml(newdata, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add WALS mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "while constructing a mapping\n",
      "  in \"../data-raw/afrobarometer-mappings/r6.yml\", line 760, column 3\n",
      "found duplicate key (note)\n",
      "  in \"../data-raw/afrobarometer-mappings/r6.yml\", line 769, column 3\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from yaml.constructor import ConstructorError\n",
    "\n",
    "try:\n",
    "    from yaml import CLoader as Loader\n",
    "except ImportError:\n",
    "    from yaml import Loader\n",
    "\n",
    "\n",
    "def no_duplicates_constructor(loader, node, deep=False):\n",
    "    \"\"\"Check for duplicate keys.\"\"\"\n",
    "\n",
    "    mapping = {}\n",
    "    for key_node, value_node in node.value:\n",
    "        key = loader.construct_object(key_node, deep=deep)\n",
    "        value = loader.construct_object(value_node, deep=deep)\n",
    "        if key in mapping:\n",
    "            raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n",
    "                                   \"found duplicate key (%s)\" % key, key_node.start_mark)\n",
    "        mapping[key] = value\n",
    "\n",
    "    return loader.construct_mapping(node, deep)\n",
    "\n",
    "yaml.add_constructor(yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG, no_duplicates_constructor)\n",
    "\n",
    "\n",
    "for r in range(1, 7):\n",
    "    try:\n",
    "        with open(\"../data-raw/afrobarometer-mappings/r%d.yml\" % r, 'r') as f:\n",
    "            yaml.load(f)\n",
    "    except ConstructorError as e:\n",
    "        print(r)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../data-raw/ethnologue-tree.json\", 'r') as f:\n",
    "    ethnologue = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def better_tree(key, tree):\n",
    "    newtree = {k: v for k, v in tree.items() if k not in ['subgroups', 'languages']}\n",
    "    newtree['path'] = key\n",
    "    newtree['language'] = 'iso_code' in tree\n",
    "    newtree['children'] = []\n",
    "    for i in ('languages', 'subgroups'):\n",
    "        if i in tree and len(tree[i]):\n",
    "            try:\n",
    "                for k, v in tree[i].items():\n",
    "                    newtree['children'] += [better_tree(k, v)]\n",
    "            except AttributeError as e:\n",
    "                raise e\n",
    "    return newtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ethnologue_tree = [better_tree(k, v) for k, v in ethnologue.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate paths for each ethnologue language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_paths(node, root = None):\n",
    "    if node['language']:\n",
    "        return [{'lang': node['iso_code'], 'path': []}]\n",
    "    else:\n",
    "        out = []\n",
    "        name = node['name']\n",
    "        for chld in node['children']:\n",
    "            for x in build_paths(chld):\n",
    "                x['path'] = [name]\n",
    "                out.append(x)\n",
    "        return out\n",
    "        \n",
    "lang_paths = {}\n",
    "for family in [build_paths(x) for x in ethnologue_tree]:\n",
    "    for x in family:\n",
    "        lang_paths[x['lang']] = {'path': x['path'], 'family': x['path'][-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with distances between languages in the ethnologue. This distance is directed. It is the distance to the closest shared ancestor on the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"../data-raw/ethnologue_dists.csv\", 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=('from', 'to', 'distance'))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(lang_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import goodtables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
